{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, \\\n",
    "average_precision_score, roc_auc_score, plot_precision_recall_curve, plot_roc_curve, plot_confusion_matrix \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, plot_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.functions import test_model, get_timeseries_table, add_model,\\\n",
    "add_hypersearch, return_score\n",
    "\n",
    "from seaborn import heatmap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67be6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(optim_result):\n",
    "    \"\"\"\n",
    "    callback for a hyperparameter search.  Displays current best score and \n",
    "    best parameters.  To be added to the fit method, callback argument.\n",
    "    \"\"\"\n",
    "    score = opt.best_score_\n",
    "    params = pd.DataFrame(opt.best_params_)\n",
    "    clear_output()\n",
    "    print('Best Score So Far: ', score)\n",
    "    print('Using Parameters: ', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f419e900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessments merged:  1\n"
     ]
    }
   ],
   "source": [
    "prediction_window = 135\n",
    "\n",
    "df = get_timeseries_table(prediction_window=prediction_window,\n",
    "                         binary_labels=True, one_hot_modules=True)\n",
    "\n",
    "X = df.drop(columns=['final_result'])\n",
    "y = df['final_result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, random_state=111)\n",
    "\n",
    "all_features = 'SMOTED activites, clicks, activities*clicks, assessments, modules'\n",
    "\n",
    "categoricals = [502, 501, 500, 499, 498, 497, 496]\n",
    "smotenc = SMOTENC(categoricals, random_state=111)\n",
    "X_train, y_train = smotenc.fit_resample(X_train, y_train)\n",
    "X_t, y_t = smotenc.fit_resample(X_t, y_t)\n",
    "\n",
    "X_t_normal = normalize(X_t)\n",
    "X_val_normal = normalize(X_val)\n",
    "X_train_normal = normalize(X_train)\n",
    "X_test_normal = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7118fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         SGDClassifier(loss='log', random_state=111),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111),      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t, y_t)\n",
    "    add_model(model, X_t, y_t, X_val, y_val, \n",
    "              preprocessing=None, \n",
    "              features = all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60130738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         CategoricalNB(),\n",
    "         GaussianNB(),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111)      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t_normal, y_t)\n",
    "    add_model(model, X_t_normal, y_t, X_val_normal, y_val, \n",
    "              features = all_features,\n",
    "              preprocessing='normalized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37004aa",
   "metadata": {},
   "source": [
    "h_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b43dbea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score So Far:  0.9344487694759113\n",
      "Using Parameters:  OrderedDict([('colsample_bytree', 0.6011694082627778), ('eval_metric', 'logloss'), ('learning_rate', 0.10937423148527929), ('max_depth', 20), ('min_child_weight', 1), ('objective', 'binary:logistic'), ('scale_pos_weight', 2.0), ('subsample', 0.8574053108878759)])\n",
      "[0.02159542 0.00311609 0.22038937 ... 0.08963265 0.00375508 0.01662309]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.701622</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.674254</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.737933</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "112  DecisionTreeClassifier     0.716129       1.000000      0.724506   \n",
       "113           SGDClassifier     0.680692       0.697458      0.701622   \n",
       "114    KNeighborsClassifier     0.674254       0.906501      0.561875   \n",
       "115    KNeighborsClassifier     0.652348       0.901600      0.556543   \n",
       "116           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "112        1.000000      0.644087        0.644087   \n",
       "113        0.695484      0.594137        0.594137   \n",
       "114        0.737933      0.575914        0.575914   \n",
       "115        0.750835      0.561319        0.561319   \n",
       "116        0.500000      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "112  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "113  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "114  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "115  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "116  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "     subsample tree_method validate_parameters  verbosity  eval_metric  \\\n",
       "0     0.857405         NaN                 NaN        NaN      logloss   \n",
       "1     1.000000         NaN                 NaN        NaN      logloss   \n",
       "2     1.000000         NaN                 NaN        NaN      logloss   \n",
       "3     1.000000         NaN                 NaN        NaN        error   \n",
       "4     1.000000         NaN                 NaN        NaN      logloss   \n",
       "..         ...         ...                 ...        ...          ...   \n",
       "112        NaN         NaN                 NaN        NaN          NaN   \n",
       "113        NaN         NaN                 NaN        NaN          NaN   \n",
       "114        NaN         NaN                 NaN        NaN          NaN   \n",
       "115        NaN         NaN                 NaN        NaN          NaN   \n",
       "116        NaN         NaN                 NaN        NaN          NaN   \n",
       "\n",
       "     class_prior fit_prior  priors var_smoothing  seed  \n",
       "0            NaN       NaN     NaN           NaN   NaN  \n",
       "1            NaN       NaN     NaN           NaN   NaN  \n",
       "2            NaN       NaN     NaN           NaN   NaN  \n",
       "3            NaN       NaN     NaN           NaN   NaN  \n",
       "4            NaN       NaN     NaN           NaN   NaN  \n",
       "..           ...       ...     ...           ...   ...  \n",
       "112          NaN       NaN     NaN           NaN   NaN  \n",
       "113          NaN       NaN     NaN           NaN   NaN  \n",
       "114          NaN       NaN     NaN           NaN   NaN  \n",
       "115          NaN       NaN     NaN           NaN   NaN  \n",
       "116          NaN      True     NaN           NaN   NaN  \n",
       "\n",
       "[115 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, seed=111, eval_metric='logloss')\n",
    "\n",
    "xgb_search_space = {'objective': Categorical(['binary:logistic',\n",
    "                                              'binary:hinge']),\n",
    "                    'eval_metric': Categorical(['logloss','error']),\n",
    "                   'learning_rate': Real(0.05, .3, 'log-uniform'),\n",
    "                   'min_child_weight': Integer(1,10, 'uniform'),\n",
    "                   'max_depth': Integer(20,60, 'normal'),\n",
    "                   'subsample': Real(0.3, 1, 'normal'),\n",
    "                   'colsample_bytree': Real(.3, 1.0, 'normal'),\n",
    "                   'scale_pos_weight': Real(.5, 2.0, 'uniform')}\n",
    "\n",
    "opt = BayesSearchCV(xgb, search_spaces=xgb_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "XGBmodel = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(XGBmodel, X_t, y_t, X_val, y_val, \n",
    "          features = all_features,\n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d0adcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model(model, X_t, y_t, X_val, y_val,\n",
    "              preprocessing=None, \n",
    "              features='Not Provided'):\n",
    "    \"\"\"\n",
    "    Scores a model by several metrics and saves it to a hyperparameter table\n",
    "    \"\"\"\n",
    "    train_probs = model.predict_proba(X_t)[:,1]\n",
    "    train_yhat = np.round_(train_probs)\n",
    "    val_probs = model.predict_proba(X_val)[:,1]\n",
    "    val_yhat = np.round_(val_probs)\n",
    "    print(val_probs)\n",
    "    parameters = {'model' : type(model).__name__,\n",
    "                  'val_roc_auc' : roc_auc_score(y_val, val_probs), \n",
    "                  'train_roc_auc': roc_auc_score(y_t, train_probs), \n",
    "                  'val_accuracy': accuracy_score(y_val, val_yhat),\n",
    "                  'train_accuracy': accuracy_score(y_t, train_yhat),\n",
    "                  'val_f1_score': f1_score(y_val, val_yhat),\n",
    "                  'train_f1_score': f1_score(y_val, val_yhat),\n",
    "                  'features': features,\n",
    "                  'preprocessing': preprocessing,\n",
    "                 }\n",
    "    parameters.update(model.get_params())\n",
    "    parameters = pd.DataFrame(parameters, index=[0])\n",
    "\n",
    "    try:\n",
    "        table = pd.read_csv('hyperparameter_table.csv')\n",
    "    except:\n",
    "        table = pd.DataFrame()\n",
    "    table = table.append(parameters, ignore_index=True)\n",
    "    table = table.drop_duplicates(subset=table.columns[7:], keep='last')\n",
    "    table = table.sort_values(by='val_roc_auc', ascending=False)\n",
    "#     table.to_csv('hyperparameter_table.csv', index=False)\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77299959",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt2 = opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07caacfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02159542 0.00311609 0.22038937 ... 0.08963265 0.00375508 0.01662309]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.701622</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.674254</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.737933</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "112  DecisionTreeClassifier     0.716129       1.000000      0.724506   \n",
       "113           SGDClassifier     0.680692       0.697458      0.701622   \n",
       "114    KNeighborsClassifier     0.674254       0.906501      0.561875   \n",
       "115    KNeighborsClassifier     0.652348       0.901600      0.556543   \n",
       "116           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "112        1.000000      0.644087        0.644087   \n",
       "113        0.695484      0.594137        0.594137   \n",
       "114        0.737933      0.575914        0.575914   \n",
       "115        0.750835      0.561319        0.561319   \n",
       "116        0.500000      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "112  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "113  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "114  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "115  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "116  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "     subsample tree_method validate_parameters  verbosity  eval_metric  \\\n",
       "0     0.857405         NaN                 NaN        NaN      logloss   \n",
       "1     1.000000         NaN                 NaN        NaN      logloss   \n",
       "2     1.000000         NaN                 NaN        NaN      logloss   \n",
       "3     1.000000         NaN                 NaN        NaN        error   \n",
       "4     1.000000         NaN                 NaN        NaN      logloss   \n",
       "..         ...         ...                 ...        ...          ...   \n",
       "112        NaN         NaN                 NaN        NaN          NaN   \n",
       "113        NaN         NaN                 NaN        NaN          NaN   \n",
       "114        NaN         NaN                 NaN        NaN          NaN   \n",
       "115        NaN         NaN                 NaN        NaN          NaN   \n",
       "116        NaN         NaN                 NaN        NaN          NaN   \n",
       "\n",
       "     class_prior fit_prior  priors var_smoothing  seed  \n",
       "0            NaN       NaN     NaN           NaN   NaN  \n",
       "1            NaN       NaN     NaN           NaN   NaN  \n",
       "2            NaN       NaN     NaN           NaN   NaN  \n",
       "3            NaN       NaN     NaN           NaN   NaN  \n",
       "4            NaN       NaN     NaN           NaN   NaN  \n",
       "..           ...       ...     ...           ...   ...  \n",
       "112          NaN       NaN     NaN           NaN   NaN  \n",
       "113          NaN       NaN     NaN           NaN   NaN  \n",
       "114          NaN       NaN     NaN           NaN   NaN  \n",
       "115          NaN       NaN     NaN           NaN   NaN  \n",
       "116          NaN      True     NaN           NaN   NaN  \n",
       "\n",
       "[115 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_model(XGBmodel, X_t, y_t, X_val, y_val, \n",
    "          features = all_features,\n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score So Far:  0.9286259802313596\n",
      "Using Parameters:  OrderedDict([('class_weight', None), ('max_depth', 46), ('max_features', 'sqrt'), ('max_samples', 0.99), ('n_estimators', 500)])\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=111)\n",
    "\n",
    "rf_search_space = {'n_estimators': Integer(50, 500, 'normal'),\n",
    "                   'max_depth': Integer(5, 50, 'normal'),\n",
    "                   'max_features': Categorical(['sqrt','log2',None]),\n",
    "                   'class_weight': Categorical(['balanced','balanced_subsample',None]),\n",
    "                   'max_samples': Real(.1, .99, 'uniform')\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(rf, search_spaces=rf_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "RFclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(RFclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615241a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state=111)\n",
    "\n",
    "DT_search_space = {'criterion': Categorical(['gini','entropy']),\n",
    "                   'splitter': Categorical(['best','random']),\n",
    "                    'max_depth': Integer(3,10, 'uniform'),\n",
    "                   'max_features': Categorical(['sqrt','log2', None]),\n",
    "                   'class_weight': Categorical(['balanced',None]),\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(DT, search_spaces=DT_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True)\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "DTclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(DTclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[table['model'] == 'XGBClassifier'].dropna(subset=['val_accuracy'], how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4414b2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = pd.read_csv('hyperparameter_table.csv')\n",
    "table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "plot_precision_recall_curve(clf, X_val, y_val, ax = axes[0])\n",
    "axes[0].set_title('Precision-Recall Curve')\n",
    "\n",
    "plot_roc_curve(clf, X_val, y_val, ax= axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_accuracy = pd.DataFrame(columns= ['accuracy', 'f1_score'],\n",
    "                              index = [x/100 for x in range(60,80)])\n",
    "\n",
    "thresh_accuracy.index.name = 'Threshold'\n",
    "for thresh in range(10, 90):\n",
    "    thresh /= 100\n",
    "    yhat = pd.Series(y_score).apply(lambda x: 1 if x >= thresh else 0)\n",
    "    accuracy = accuracy_score(y_val, yhat)\n",
    "    f1 = f1_score(y_val, yhat)\n",
    "    roc = roc_auc_score(y_val, y_score)\n",
    "    pr = average_precision_score(y_val, y_score)\n",
    "    thresh_accuracy.loc[thresh, 'accuracy'] = accuracy\n",
    "    thresh_accuracy.loc[thresh, 'f1_score'] = f1\n",
    "\n",
    "print('ROC_AUC: ', roc)\n",
    "print('PR_AUC: ', pr)\n",
    "thresh_accuracy = thresh_accuracy.sort_values(by='f1_score', ascending=False)\n",
    "thresh_accuracy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pd.Series(y_score)\n",
    "best_thresh = thresh_accuracy.index[0]\n",
    "yhat = yhat.apply(lambda x: 1 if x >= best_thresh else 0)\n",
    "\n",
    "confusion  = confusion_matrix(y_val, yhat, normalize='true')\n",
    "heatmap(confusion, annot=True, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cfbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(XGBmodel.feature_importances_, index=X_t.columns)\n",
    "importance.sort_values(by=0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a863fa",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('time_series_xgb_best.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6748e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student_predictor_env",
   "language": "python",
   "name": "student_predictor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
