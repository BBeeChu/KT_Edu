{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, \\\n",
    "average_precision_score, roc_auc_score, plot_precision_recall_curve, plot_roc_curve, plot_confusion_matrix \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, plot_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.functions import test_model, get_timeseries_table, add_model,\\\n",
    "add_hypersearch\n",
    "\n",
    "from seaborn import heatmap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3590906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(optim_result):\n",
    "    \"\"\"\n",
    "    callback for a hyperparameter search.  Displays current best score and \n",
    "    best parameters.  To be added to the fit method, callback argument.\n",
    "    \"\"\"\n",
    "    score = opt.best_score_\n",
    "    params = pd.DataFrame(opt.best_params_)\n",
    "    clear_output()\n",
    "    print('Best Score So Far: ', score)\n",
    "    print('Using Parameters: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953af53",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We start off by loading our data.  We only load data from the first half of the course because we want to identify students who may need intervention while there is still time for intervention to be effective.  The courses are 270 days long, so we load the first 135 days worth of data to use to make our predictions.  This date can be pushed forward by changing the `prediction_window` variable.  Later predictions are more accurate, earlier predictions can lead to more successful interventions.  It should be noted that these courses are self-paced, but assessments do have due dates.\n",
    "\n",
    "This data, after preprocessing the given trace data, contains several columns for each day of the course, up to the date we choose to make our prediction.  These metrics are:\n",
    "\n",
    "1. Number of activities completed on each day.  Activities vary from web links to quizzes.\n",
    "\n",
    "2. Number of clicks each day.\n",
    "\n",
    "3. A polynomial feature, clicks * activities, to capture the fact that different activities require different numbers of clicks.\n",
    "\n",
    "The last rows are not timeseries, but have to do with assessments and the course module that the data comes from.\n",
    "\n",
    "4. Assessment scores for each completed assessment.  I found in previous models that assessment scores are highly predictive of course outcomes. \n",
    "\n",
    "5. The timing of the assessment completion.  In previous exploration, there was a correlation between when students completed assessments and course outcomes.  Completing more assessments earlier in the course correlated to a greater chance of passing the course.\n",
    "\n",
    "6. One-hot-encoding of the course module code.  The course modules vary greatly in their pass/fail rates, average clicks and activities, and assessment scores.  Which course a student is taking is highly correlated to whether they will pass it. As you will see in the final model feature importances at the end of this notebook.\n",
    "\n",
    "## Class Balance\n",
    "\n",
    "The pass/fail ratio is about 3 to 1.  This is not such a terrible class balance, but my models consistently over-predict students to pass, and using the synthetic data oversampling technique called SMOTE helps to prevent the models from learning to just default to pass to improve their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 135\n",
    "\n",
    "df = get_timeseries_table(prediction_window=prediction_window,\n",
    "                         binary_labels=True, one_hot_modules=True)\n",
    "\n",
    "X = df.drop(columns=['final_result'])\n",
    "y = df['final_result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, random_state=111)\n",
    "\n",
    "all_features = 'SMOTED activites, clicks, activities*clicks, assessments, modules'\n",
    "\n",
    "categoricals = [502, 501, 500, 499, 498, 497, 496]\n",
    "smotenc = SMOTENC(categoricals, random_state=111)\n",
    "X_train, y_train = smotenc.fit_resample(X_train, y_train)\n",
    "X_t, y_t = smotenc.fit_resample(X_t, y_t)\n",
    "\n",
    "X_t_normal = normalize(X_t)\n",
    "X_val_normal = normalize(X_val)\n",
    "X_train_normal = normalize(X_train)\n",
    "X_test_normal = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef57a7e",
   "metadata": {},
   "source": [
    "# Choosing from available models\n",
    "\n",
    "We will try several out of the box models on this data to see, in broad terms, which model might be most successful.  Later we will choose the most accurate ones and tune their parameters to make a final determination on which one to use.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "I chose ROC AUC as my target metric because we have an opportunity to tune the probability thresholds on the final model to find the right balance between recall and precision in the final classifier.  I want the model that performs best over all thresholds, so future stakeholders can make choices about how to balance unnecessary interventions and students needing intervention that don't get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7118fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         SGDClassifier(loss='log', random_state=111),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111),      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t, y_t)\n",
    "    add_model(model, X_t, y_t, X_val, y_val, \n",
    "              preprocessing=None, \n",
    "              features = all_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf49be",
   "metadata": {},
   "source": [
    "## Does normalizig the data help?\n",
    "\n",
    "We need to normalize data to try Naive Bayes models anyway, so I decided to try them all with normally distritbuted data, just in case it helps.  It turns out that Bayesian models are not the right model for this problem, and normalizing the data didn't help the others much.  But, it was worth a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60130738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         CategoricalNB(),\n",
    "         GaussianNB(),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111)      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t_normal, y_t)\n",
    "    add_model(model, X_t_normal, y_t, X_val_normal, y_val, \n",
    "              features = all_features,\n",
    "              preprocessing='normalized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "612a7cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.666581</td>\n",
       "      <td>0.675585</td>\n",
       "      <td>0.676294</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>0.585255</td>\n",
       "      <td>0.585255</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.664188</td>\n",
       "      <td>0.826102</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.743001</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.647906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.601601</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.642942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "189           SGDClassifier     0.666581       0.675585      0.676294   \n",
       "190    KNeighborsClassifier     0.664188       0.826102      0.622084   \n",
       "191  DecisionTreeClassifier     0.641270       0.647906           NaN   \n",
       "192  DecisionTreeClassifier     0.601601       0.610556           NaN   \n",
       "193           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "189        0.681899      0.585255        0.585255   \n",
       "190        0.743001      0.539399        0.539399   \n",
       "191             NaN           NaN             NaN   \n",
       "192             NaN           NaN             NaN   \n",
       "193        0.642942      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "189  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "190  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "191                                                NaN           NaN NaN  ...   \n",
       "192                                                NaN           NaN NaN  ...   \n",
       "193  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "    scale_pos_weight subsample tree_method  validate_parameters  verbosity  \\\n",
       "0                2.0  0.857405         NaN                  NaN        NaN   \n",
       "1                2.0  1.000000         NaN                  NaN        NaN   \n",
       "2                2.0  1.000000         NaN                  NaN        NaN   \n",
       "3                2.0  1.000000         NaN                  NaN        NaN   \n",
       "4                2.0  1.000000         NaN                  NaN        NaN   \n",
       "..               ...       ...         ...                  ...        ...   \n",
       "189              NaN       NaN         NaN                  NaN        NaN   \n",
       "190              NaN       NaN         NaN                  NaN        NaN   \n",
       "191              NaN       NaN         NaN                  NaN        NaN   \n",
       "192              NaN       NaN         NaN                  NaN        NaN   \n",
       "193              NaN       NaN         NaN                  NaN        NaN   \n",
       "\n",
       "     eval_metric class_prior  fit_prior priors  var_smoothing  \n",
       "0        logloss         NaN        NaN    NaN            NaN  \n",
       "1        logloss         NaN        NaN    NaN            NaN  \n",
       "2        logloss         NaN        NaN    NaN            NaN  \n",
       "3          error         NaN        NaN    NaN            NaN  \n",
       "4        logloss         NaN        NaN    NaN            NaN  \n",
       "..           ...         ...        ...    ...            ...  \n",
       "189          NaN         NaN        NaN    NaN            NaN  \n",
       "190          NaN         NaN        NaN    NaN            NaN  \n",
       "191          NaN         NaN        NaN    NaN            NaN  \n",
       "192          NaN         NaN        NaN    NaN            NaN  \n",
       "193          NaN         NaN       True    NaN            NaN  \n",
       "\n",
       "[194 rows x 95 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('hyperparameter_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8d37e",
   "metadata": {},
   "source": [
    "## Model shortlist\n",
    "\n",
    "It turns out the tree based models are performing best on this data.  We will take the XGBoost, Random Forest, and Decision Tree models forward and see if we can tune the hyperparameters to achieve a better ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b43dbea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score So Far:  0.9344487694759113\n",
      "Using Parameters:  OrderedDict([('colsample_bytree', 0.6011694082627778), ('eval_metric', 'logloss'), ('learning_rate', 0.10937423148527929), ('max_depth', 20), ('min_child_weight', 1), ('objective', 'binary:logistic'), ('scale_pos_weight', 2.0), ('subsample', 0.8574053108878759)])\n",
      "[0.02159542 0.00311609 0.22038937 ... 0.08963265 0.00375508 0.01662309]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.701622</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.674254</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.737933</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "112  DecisionTreeClassifier     0.716129       1.000000      0.724506   \n",
       "113           SGDClassifier     0.680692       0.697458      0.701622   \n",
       "114    KNeighborsClassifier     0.674254       0.906501      0.561875   \n",
       "115    KNeighborsClassifier     0.652348       0.901600      0.556543   \n",
       "116           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "112        1.000000      0.644087        0.644087   \n",
       "113        0.695484      0.594137        0.594137   \n",
       "114        0.737933      0.575914        0.575914   \n",
       "115        0.750835      0.561319        0.561319   \n",
       "116        0.500000      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "112  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "113  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "114  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "115  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "116  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "     subsample tree_method validate_parameters  verbosity  eval_metric  \\\n",
       "0     0.857405         NaN                 NaN        NaN      logloss   \n",
       "1     1.000000         NaN                 NaN        NaN      logloss   \n",
       "2     1.000000         NaN                 NaN        NaN      logloss   \n",
       "3     1.000000         NaN                 NaN        NaN        error   \n",
       "4     1.000000         NaN                 NaN        NaN      logloss   \n",
       "..         ...         ...                 ...        ...          ...   \n",
       "112        NaN         NaN                 NaN        NaN          NaN   \n",
       "113        NaN         NaN                 NaN        NaN          NaN   \n",
       "114        NaN         NaN                 NaN        NaN          NaN   \n",
       "115        NaN         NaN                 NaN        NaN          NaN   \n",
       "116        NaN         NaN                 NaN        NaN          NaN   \n",
       "\n",
       "     class_prior fit_prior  priors var_smoothing  seed  \n",
       "0            NaN       NaN     NaN           NaN   NaN  \n",
       "1            NaN       NaN     NaN           NaN   NaN  \n",
       "2            NaN       NaN     NaN           NaN   NaN  \n",
       "3            NaN       NaN     NaN           NaN   NaN  \n",
       "4            NaN       NaN     NaN           NaN   NaN  \n",
       "..           ...       ...     ...           ...   ...  \n",
       "112          NaN       NaN     NaN           NaN   NaN  \n",
       "113          NaN       NaN     NaN           NaN   NaN  \n",
       "114          NaN       NaN     NaN           NaN   NaN  \n",
       "115          NaN       NaN     NaN           NaN   NaN  \n",
       "116          NaN      True     NaN           NaN   NaN  \n",
       "\n",
       "[115 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, seed=111, eval_metric='logloss')\n",
    "\n",
    "xgb_search_space = {'objective': Categorical(['binary:logistic',\n",
    "                                              'binary:hinge']),\n",
    "                    'eval_metric': Categorical(['logloss','error']),\n",
    "                   'learning_rate': Real(0.05, .3, 'log-uniform'),\n",
    "                   'min_child_weight': Integer(1,10, 'uniform'),\n",
    "                   'max_depth': Integer(20,60, 'normal'),\n",
    "                   'subsample': Real(0.3, 1, 'normal'),\n",
    "                   'colsample_bytree': Real(.3, 1.0, 'normal'),\n",
    "                   'scale_pos_weight': Real(.5, 2.0, 'uniform')}\n",
    "\n",
    "opt = BayesSearchCV(xgb, search_spaces=xgb_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "XGBmodel = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(XGBmodel, X_t, y_t, X_val, y_val, \n",
    "          features = all_features,\n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d4c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score So Far:  0.9287414529982579\n",
      "Using Parameters:  OrderedDict([('class_weight', None), ('max_depth', 50), ('max_features', 'sqrt'), ('max_samples', 0.99), ('n_estimators', 500)])\n",
      "[0.148 0.092 0.234 ... 0.272 0.082 0.206]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.701622</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.674254</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.737933</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "159  DecisionTreeClassifier     0.716129       1.000000      0.724506   \n",
       "160           SGDClassifier     0.680692       0.697458      0.701622   \n",
       "161    KNeighborsClassifier     0.674254       0.906501      0.561875   \n",
       "162    KNeighborsClassifier     0.652348       0.901600      0.556543   \n",
       "163           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "159        1.000000      0.644087        0.644087   \n",
       "160        0.695484      0.594137        0.594137   \n",
       "161        0.737933      0.575914        0.575914   \n",
       "162        0.750835      0.561319        0.561319   \n",
       "163        0.500000      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "159  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "160  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "161  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "162  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "163  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "    scale_pos_weight subsample tree_method  validate_parameters  verbosity  \\\n",
       "0                2.0  0.857405         NaN                  NaN        NaN   \n",
       "1                2.0  1.000000         NaN                  NaN        NaN   \n",
       "2                2.0  1.000000         NaN                  NaN        NaN   \n",
       "3                2.0  1.000000         NaN                  NaN        NaN   \n",
       "4                2.0  1.000000         NaN                  NaN        NaN   \n",
       "..               ...       ...         ...                  ...        ...   \n",
       "159              NaN       NaN         NaN                  NaN        NaN   \n",
       "160              NaN       NaN         NaN                  NaN        NaN   \n",
       "161              NaN       NaN         NaN                  NaN        NaN   \n",
       "162              NaN       NaN         NaN                  NaN        NaN   \n",
       "163              NaN       NaN         NaN                  NaN        NaN   \n",
       "\n",
       "     eval_metric class_prior fit_prior priors  var_smoothing  \n",
       "0        logloss         NaN       NaN    NaN            NaN  \n",
       "1        logloss         NaN       NaN    NaN            NaN  \n",
       "2        logloss         NaN       NaN    NaN            NaN  \n",
       "3          error         NaN       NaN    NaN            NaN  \n",
       "4        logloss         NaN       NaN    NaN            NaN  \n",
       "..           ...         ...       ...    ...            ...  \n",
       "159          NaN         NaN       NaN    NaN            NaN  \n",
       "160          NaN         NaN       NaN    NaN            NaN  \n",
       "161          NaN         NaN       NaN    NaN            NaN  \n",
       "162          NaN         NaN       NaN    NaN            NaN  \n",
       "163          NaN         NaN      True    NaN            NaN  \n",
       "\n",
       "[165 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=111)\n",
    "\n",
    "rf_search_space = {'n_estimators': Integer(50, 500, 'normal'),\n",
    "                   'max_depth': Integer(5, 50, 'normal'),\n",
    "                   'max_features': Categorical(['sqrt','log2',None]),\n",
    "                   'class_weight': Categorical(['balanced','balanced_subsample',None]),\n",
    "                   'max_samples': Real(.1, .99, 'uniform')\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(rf, search_spaces=rf_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "RFclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(RFclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "615241a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score So Far:  0.8580704609462663\n",
      "Using Parameters:  OrderedDict([('class_weight', 'balanced'), ('criterion', 'entropy'), ('max_depth', 6), ('max_features', None), ('splitter', 'best')])\n",
      "[0.02105263 0.10779436 0.59214502 ... 0.59214502 0.02105263 0.12004802]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>features</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>subsample</th>\n",
       "      <th>tree_method</th>\n",
       "      <th>validate_parameters</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>class_prior</th>\n",
       "      <th>fit_prior</th>\n",
       "      <th>priors</th>\n",
       "      <th>var_smoothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.674254</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.737933</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.556543</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>0.561319</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.647906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.601601</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636303</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SMOTED activites, clicks, activities*clicks, a...</td>\n",
       "      <td>normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  val_roc_auc  train_roc_auc  val_accuracy  \\\n",
       "0             XGBClassifier     0.934449       1.000000           NaN   \n",
       "1             XGBClassifier     0.934330       0.999999           NaN   \n",
       "2             XGBClassifier     0.933969       1.000000           NaN   \n",
       "3             XGBClassifier     0.933770       1.000000           NaN   \n",
       "4             XGBClassifier     0.933645       0.999990           NaN   \n",
       "..                      ...          ...            ...           ...   \n",
       "188    KNeighborsClassifier     0.674254       0.906501      0.561875   \n",
       "189    KNeighborsClassifier     0.652348       0.901600      0.556543   \n",
       "190  DecisionTreeClassifier     0.641270       0.647906           NaN   \n",
       "191  DecisionTreeClassifier     0.601601       0.610556           NaN   \n",
       "192           CategoricalNB     0.500000       0.500000      0.636303   \n",
       "\n",
       "     train_accuracy  val_f1_score  train_f1_score  \\\n",
       "0               NaN           NaN             NaN   \n",
       "1               NaN           NaN             NaN   \n",
       "2               NaN           NaN             NaN   \n",
       "3               NaN           NaN             NaN   \n",
       "4               NaN           NaN             NaN   \n",
       "..              ...           ...             ...   \n",
       "188        0.737933      0.575914        0.575914   \n",
       "189        0.750835      0.561319        0.561319   \n",
       "190             NaN           NaN             NaN   \n",
       "191             NaN           NaN             NaN   \n",
       "192        0.500000      0.000000        0.000000   \n",
       "\n",
       "                                              features preprocessing   C  ...  \\\n",
       "0                                                  NaN           NaN NaN  ...   \n",
       "1                                                  NaN           NaN NaN  ...   \n",
       "2                                                  NaN           NaN NaN  ...   \n",
       "3                                                  NaN           NaN NaN  ...   \n",
       "4                                                  NaN           NaN NaN  ...   \n",
       "..                                                 ...           ...  ..  ...   \n",
       "188  SMOTED activites, clicks, activities*clicks, a...           NaN NaN  ...   \n",
       "189  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "190                                                NaN           NaN NaN  ...   \n",
       "191                                                NaN           NaN NaN  ...   \n",
       "192  SMOTED activites, clicks, activities*clicks, a...    normalized NaN  ...   \n",
       "\n",
       "    scale_pos_weight subsample tree_method  validate_parameters  verbosity  \\\n",
       "0                2.0  0.857405         NaN                  NaN        NaN   \n",
       "1                2.0  1.000000         NaN                  NaN        NaN   \n",
       "2                2.0  1.000000         NaN                  NaN        NaN   \n",
       "3                2.0  1.000000         NaN                  NaN        NaN   \n",
       "4                2.0  1.000000         NaN                  NaN        NaN   \n",
       "..               ...       ...         ...                  ...        ...   \n",
       "188              NaN       NaN         NaN                  NaN        NaN   \n",
       "189              NaN       NaN         NaN                  NaN        NaN   \n",
       "190              NaN       NaN         NaN                  NaN        NaN   \n",
       "191              NaN       NaN         NaN                  NaN        NaN   \n",
       "192              NaN       NaN         NaN                  NaN        NaN   \n",
       "\n",
       "     eval_metric class_prior  fit_prior priors  var_smoothing  \n",
       "0        logloss         NaN        NaN    NaN            NaN  \n",
       "1        logloss         NaN        NaN    NaN            NaN  \n",
       "2        logloss         NaN        NaN    NaN            NaN  \n",
       "3          error         NaN        NaN    NaN            NaN  \n",
       "4        logloss         NaN        NaN    NaN            NaN  \n",
       "..           ...         ...        ...    ...            ...  \n",
       "188          NaN         NaN        NaN    NaN            NaN  \n",
       "189          NaN         NaN        NaN    NaN            NaN  \n",
       "190          NaN         NaN        NaN    NaN            NaN  \n",
       "191          NaN         NaN        NaN    NaN            NaN  \n",
       "192          NaN         NaN       True    NaN            NaN  \n",
       "\n",
       "[194 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier(random_state=111)\n",
    "\n",
    "DT_search_space = {'criterion': Categorical(['gini','entropy']),\n",
    "                   'splitter': Categorical(['best','random']),\n",
    "                    'max_depth': Integer(3,10, 'uniform'),\n",
    "                   'max_features': Categorical(['sqrt','log2', None]),\n",
    "                   'class_weight': Categorical(['balanced',None]),\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(DT, search_spaces=DT_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True)\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "DTclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(DTclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c590f",
   "metadata": {},
   "source": [
    "# Final model:  XGBoost\n",
    "\n",
    "XGBoost, a tree based boosting ensemble model, has shown great success in Kaggle competitions, and has been a great model for previous projects.  I'm not surprised it provides the best results here.  Let's explore this model a little more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6580ff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                                                  NaN\n",
       "101                                                  NaN\n",
       "102                                                  NaN\n",
       "103                                                  NaN\n",
       "104                                                  NaN\n",
       "105                                                  NaN\n",
       "106                                                  NaN\n",
       "107                                                  NaN\n",
       "108                                                  NaN\n",
       "109                                                  NaN\n",
       "110                                                  NaN\n",
       "111                                                  NaN\n",
       "112                                                  NaN\n",
       "113                                                  NaN\n",
       "114                                                  NaN\n",
       "115                                                  NaN\n",
       "116                                                  NaN\n",
       "117                                                  NaN\n",
       "118                                                  NaN\n",
       "119                                                  NaN\n",
       "120                                                  NaN\n",
       "121                                                  NaN\n",
       "122                                                  NaN\n",
       "123                                                  NaN\n",
       "124                                                  NaN\n",
       "125                                                  NaN\n",
       "126                                                  NaN\n",
       "127    SMOTED activites, clicks, activities*clicks, a...\n",
       "128                                                  NaN\n",
       "129                                                  NaN\n",
       "130                                                  NaN\n",
       "131                                                  NaN\n",
       "132                                                  NaN\n",
       "133                                                  NaN\n",
       "134                                                  NaN\n",
       "135    SMOTED activites, clicks, activities*clicks, a...\n",
       "136                                                  NaN\n",
       "137    SMOTED activites, clicks, activities*clicks, a...\n",
       "138    SMOTED activites, clicks, activities*clicks, a...\n",
       "139                                                  NaN\n",
       "140                                                  NaN\n",
       "141                                                  NaN\n",
       "142                                                  NaN\n",
       "143                                                  NaN\n",
       "144                                                  NaN\n",
       "145                                                  NaN\n",
       "146                                                  NaN\n",
       "147                                                  NaN\n",
       "148                                                  NaN\n",
       "149    SMOTED activites, clicks, activities*clicks, a...\n",
       "Name: features, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['features'][100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96a5bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ba7e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_score = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "plot_precision_recall_curve(clf, X_val, y_val, ax = axes[0])\n",
    "axes[0].set_title('Precision-Recall Curve')\n",
    "\n",
    "plot_roc_curve(clf, X_val, y_val, ax= axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4983d",
   "metadata": {},
   "source": [
    "## Probability Threshold\n",
    "\n",
    "I mentioned before that we can tune the threshold probability that our model uses to classify a student as likely to pass or likely not to.  Let's take a look at which thresholds give us the best overall accuracy and F1 score.  I also use F1 score because it gives me an idea of both prevision and recall, where accuracy can be confounded by class imbalance in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dfc7acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC:  0.9028329260843004\n",
      "PR_AUC:  0.8788171438638057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.84359</td>\n",
       "      <td>0.774936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.51</th>\n",
       "      <td>0.84359</td>\n",
       "      <td>0.774214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.49</th>\n",
       "      <td>0.842479</td>\n",
       "      <td>0.774132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.839369</td>\n",
       "      <td>0.773283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48</th>\n",
       "      <td>0.840702</td>\n",
       "      <td>0.772598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.46</th>\n",
       "      <td>0.839147</td>\n",
       "      <td>0.77247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>0.842702</td>\n",
       "      <td>0.772347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.47</th>\n",
       "      <td>0.839369</td>\n",
       "      <td>0.771852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.44</th>\n",
       "      <td>0.837369</td>\n",
       "      <td>0.771393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.53</th>\n",
       "      <td>0.842479</td>\n",
       "      <td>0.771217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.54</th>\n",
       "      <td>0.842924</td>\n",
       "      <td>0.770827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.31</th>\n",
       "      <td>0.82715</td>\n",
       "      <td>0.770501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>0.846479</td>\n",
       "      <td>0.769743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.59</th>\n",
       "      <td>0.844701</td>\n",
       "      <td>0.769535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.845146</td>\n",
       "      <td>0.769282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.58</th>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>0.817596</td>\n",
       "      <td>0.769058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.33</th>\n",
       "      <td>0.827816</td>\n",
       "      <td>0.769001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.82515</td>\n",
       "      <td>0.768733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.43</th>\n",
       "      <td>0.834481</td>\n",
       "      <td>0.768562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1_score\n",
       "Threshold                    \n",
       "0.50        0.84359  0.774936\n",
       "0.51        0.84359  0.774214\n",
       "0.49       0.842479  0.774132\n",
       "0.45       0.839369  0.773283\n",
       "0.48       0.840702  0.772598\n",
       "0.46       0.839147   0.77247\n",
       "0.52       0.842702  0.772347\n",
       "0.47       0.839369  0.771852\n",
       "0.44       0.837369  0.771393\n",
       "0.53       0.842479  0.771217\n",
       "0.54       0.842924  0.770827\n",
       "0.31        0.82715  0.770501\n",
       "0.62       0.846479  0.769743\n",
       "0.59       0.844701  0.769535\n",
       "0.60       0.845146  0.769282\n",
       "0.58       0.844035  0.769231\n",
       "0.22       0.817596  0.769058\n",
       "0.33       0.827816  0.769001\n",
       "0.30        0.82515  0.768733\n",
       "0.43       0.834481  0.768562"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_accuracy = pd.DataFrame(columns= ['accuracy', 'f1_score'],\n",
    "                              index = [x/100 for x in range(60,80)])\n",
    "\n",
    "thresh_accuracy.index.name = 'Threshold'\n",
    "for thresh in range(10, 90):\n",
    "    thresh /= 100\n",
    "    yhat = pd.Series(y_score).apply(lambda x: 1 if x >= thresh else 0)\n",
    "    accuracy = accuracy_score(y_val, yhat)\n",
    "    f1 = f1_score(y_val, yhat)\n",
    "    roc = roc_auc_score(y_val, y_score)\n",
    "    pr = average_precision_score(y_val, y_score)\n",
    "    thresh_accuracy.loc[thresh, 'accuracy'] = accuracy\n",
    "    thresh_accuracy.loc[thresh, 'f1_score'] = f1\n",
    "\n",
    "print('ROC_AUC: ', roc)\n",
    "print('PR_AUC: ', pr)\n",
    "thresh_accuracy = thresh_accuracy.sort_values(by='f1_score', ascending=False)\n",
    "thresh_accuracy.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b6a51",
   "metadata": {},
   "source": [
    "## Tuning the prediction probability threshold\n",
    "\n",
    "It turns out that a probability threshold of 50% gives us the best F1 score.  This means targeting ROC AUC as a metric was probably a good idea. Again, the real purpose of this is not to find a better accuracy at a different threshold, but to give stakeholders the ability to tune the model and it's predictions.  If interventions are cheap, they may want to minimize students who need, but don't get interventions, false negatives.  If interventions are expensive or disruptive, we can minimize the number of students who get interventions they don't need, or false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a26da",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The confusion matrix below is normalized across the true axis.  The top two boxes represent students who will truly pass the course.  The box in the top left is the percentage of passing students that the model accurately labeled as passing, and the to right is the percent of passing students labeled as likely not to pass, to fail or withdraw early.  Similarly the bottom left are students who will not pass, but the model predicts they will, and the bottom right are the percentage of students who will not pass that the model accurately predicts.\n",
    "\n",
    "We see here that the model still is over predicting student success.  26% of student in need of intervention will not receive it.  However, only 10% of students that model suggests for intervention will not need it.  I think there are just a lot of students who seem like they should pass, but don't.  Sometimes life happens, even to a strong student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cde5a2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = pd.Series(y_score)\n",
    "best_thresh = thresh_accuracy.index[0]\n",
    "yhat = yhat.apply(lambda x: 1 if x >= best_thresh else 0)\n",
    "\n",
    "confusion  = confusion_matrix(y_val, yhat, normalize='true')\n",
    "heatmap(confusion, annot=True, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11783a2",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "The below chart ranks the importance of each feature, according to the XGBoost model, from most important leas important.  It seems that whether or not the student is taking the module coded as `GGG` is a big predictor!  It may be that this is the hardest, or easiest of the modules.  We can explore this more later.  We also see that other modules rank high on the list.  It seems that which course a student is in plays an outsized role in determining success.  This might be worth the university's time to look into.  Are some students in courses they aren't prepared for?  Are some instructors going to easy on students in some courses?\n",
    "\n",
    "We also see that student scores on the 2nd and 3rd assessments are highly predictive.  I knew from previous work that assessment scores were very predictive of success, but this chart shows that some may be more predictive than others.  The first assessments of a module are not important enough to even show up in the top 20 variables, where as the 2nd and 3rd are both in the top 3.  This is a very interesting result, and could be the focus of future study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "994cfbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>module_GGG</th>\n",
       "      <td>0.023402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_score_3</th>\n",
       "      <td>0.019110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_score_2</th>\n",
       "      <td>0.015450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module_CCC</th>\n",
       "      <td>0.012348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module_AAA</th>\n",
       "      <td>0.009090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_124</th>\n",
       "      <td>0.007640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_x_clicks_-23</th>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_score_4</th>\n",
       "      <td>0.007045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_click_-19</th>\n",
       "      <td>0.006608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module_EEE</th>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_score_7</th>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_submitted_2</th>\n",
       "      <td>0.005888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_132</th>\n",
       "      <td>0.005753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_131</th>\n",
       "      <td>0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assess_submitted_7</th>\n",
       "      <td>0.005576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module_FFF</th>\n",
       "      <td>0.005374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_122</th>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_130</th>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_129</th>\n",
       "      <td>0.004884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_activities_123</th>\n",
       "      <td>0.004728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "module_GGG               0.023402\n",
       "assess_score_3           0.019110\n",
       "assess_score_2           0.015450\n",
       "module_CCC               0.012348\n",
       "module_AAA               0.009090\n",
       "sum_activities_124       0.007640\n",
       "activities_x_clicks_-23  0.007129\n",
       "assess_score_4           0.007045\n",
       "sum_click_-19            0.006608\n",
       "module_EEE               0.006407\n",
       "assess_score_7           0.006297\n",
       "assess_submitted_2       0.005888\n",
       "sum_activities_132       0.005753\n",
       "sum_activities_131       0.005691\n",
       "assess_submitted_7       0.005576\n",
       "module_FFF               0.005374\n",
       "sum_activities_122       0.005192\n",
       "sum_activities_130       0.004973\n",
       "sum_activities_129       0.004884\n",
       "sum_activities_123       0.004728"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(XGBmodel.feature_importances_, index=X_t.columns)\n",
    "importance.sort_values(by=0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fcda229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('time_series_xgb_best.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6871471",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "XGBoost was our most successfuly classifier for recommending interventions for students.  It successfully recommends interventions for 74% of students that need them, while recommending interventions for 10% of students who don't need them.  These numbers could bear improvement, but show proof of concept that student/virtual learning environment interactions can be used to predict student success.\n",
    "\n",
    "It's also important to keep in mind which course a student is enrolled in.  It should not be surprising that some college courses are harder than others.  That's kind of common sense.\n",
    "\n",
    "# Future research\n",
    "\n",
    "Future researchers for this dataset might try correlating the types of activities students engage each day with student success.  Some information on this is available in the raw dataset.\n",
    "\n",
    "They also might look more closely at why early, but not the first, assessment scores are so important.  It may be that reaching out to students who perform poorly on the 2nd and 3rd assessments would be a quick way to target interventions.  Maybe most students are energized to do well on the first assessment, or that first assessments tend to be easier.  There is room for study here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea05e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student_predictor_env",
   "language": "python",
   "name": "student_predictor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
