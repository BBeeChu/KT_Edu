{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, \\\n",
    "average_precision_score, roc_auc_score, plot_precision_recall_curve, plot_roc_curve, plot_confusion_matrix \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, plot_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.functions import test_model, get_timeseries_table, add_model,\\\n",
    "add_hypersearch, return_score\n",
    "\n",
    "from seaborn import heatmap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8e4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(optim_result):\n",
    "    \"\"\"\n",
    "    callback for a hyperparameter search.  Displays current best score and \n",
    "    best parameters.  To be added to the fit method, callback argument.\n",
    "    \"\"\"\n",
    "    score = opt.best_score_\n",
    "    params = pd.DataFrame(opt.best_params_)\n",
    "    clear_output()\n",
    "    print('Best Score So Far: ', score)\n",
    "    print('Using Parameters: ', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f419e900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessments merged:  1\n"
     ]
    }
   ],
   "source": [
    "prediction_window = 135\n",
    "\n",
    "df = get_timeseries_table(prediction_window=prediction_window,\n",
    "                         binary_labels=True, one_hot_modules=True)\n",
    "\n",
    "X = df.drop(columns=['final_result'])\n",
    "y = df['final_result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, random_state=111)\n",
    "\n",
    "all_features = 'SMOTED activites, clicks, activities*clicks, assessments, modules'\n",
    "\n",
    "X_t_normal = normalize(X_t)\n",
    "X_val_normal = normalize(X_val)\n",
    "X_train_normal = normalize(X_train)\n",
    "X_test_normal = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7118fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'hyperparameter_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b36783739e10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     add_model(model, X_t, y_t, X_val, y_val, \n\u001b[0m\u001b[0;32m     14\u001b[0m               \u001b[0mpreprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m               features = all_features)\n",
      "\u001b[1;32m~\\data_science\\data_science_projects\\ou_students\\src\\functions.py\u001b[0m in \u001b[0;36madd_model\u001b[1;34m(model, X_t, y_t, X_val, y_val, preprocessing, features)\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'last'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hyperparameter_table.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\student_predictor_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\student_predictor_env\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\student_predictor_env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\student_predictor_env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'hyperparameter_table.csv'"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         SGDClassifier(loss='log', random_state=111),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111),      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t, y_t)\n",
    "    add_model(model, X_t, y_t, X_val, y_val, \n",
    "              preprocessing=None, \n",
    "              features = all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60130738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=111, solver='liblinear'),\n",
    "         DecisionTreeClassifier(random_state=111),\n",
    "         RandomForestClassifier(random_state=111),\n",
    "         CategoricalNB(),\n",
    "         GaussianNB(),\n",
    "         KNeighborsClassifier(),\n",
    "         SVC(random_state=111, probability=True),\n",
    "         AdaBoostClassifier(random_state=111),\n",
    "         XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=111)      \n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_t_normal, y_t)\n",
    "    add_model(model, X_t_normal, y_t, X_val_normal, y_val, \n",
    "              features = all_features,\n",
    "              preprocessing='normalized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37004aa",
   "metadata": {},
   "source": [
    "h_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dbea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, seed=111, eval_metric='logloss')\n",
    "\n",
    "xgb_search_space = {'objective': Categorical(['binary:logistic',\n",
    "                                              'binary:hinge']),\n",
    "                    'eval_metric': Categorical(['logloss','error']),\n",
    "                   'learning_rate': Real(0.05, .3, 'log-uniform'),\n",
    "                   'min_child_weight': Integer(1,10, 'uniform'),\n",
    "                   'max_depth': Integer(20,60, 'normal'),\n",
    "                   'subsample': Real(0.3, 1, 'normal'),\n",
    "                   'colsample_bytree': Real(.3, 1.0, 'normal'),\n",
    "                   'scale_pos_weight': Real(.5, 2.0, 'uniform')}\n",
    "\n",
    "opt = BayesSearchCV(xgb, search_spaces=xgb_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "XGBmodel = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(XGBmodel, X_t, y_t, X_val, y_val, \n",
    "          features = all_features,\n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=111)\n",
    "\n",
    "rf_search_space = {'n_estimators': Integer(50, 500, 'normal'),\n",
    "                   'max_depth': Integer(5, 50, 'normal'),\n",
    "                   'max_features': Categorical(['sqrt','log2',None]),\n",
    "                   'class_weight': Categorical(['balanced','balanced_subsample',None]),\n",
    "                   'max_samples': Real(.1, .99, 'uniform')\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(rf, search_spaces=rf_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    return_train_score=True,\n",
    "                    scoring='roc_auc')\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "RFclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(RFclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615241a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state=111)\n",
    "\n",
    "DT_search_space = {'criterion': Categorical(['gini','entropy']),\n",
    "                   'splitter': Categorical(['best','random']),\n",
    "                    'max_depth': Integer(3,10, 'uniform'),\n",
    "                   'max_features': Categorical(['sqrt','log2', None]),\n",
    "                   'class_weight': Categorical(['balanced',None]),\n",
    "                   }\n",
    "\n",
    "opt = BayesSearchCV(DT, search_spaces=DT_search_space, \n",
    "                    n_iter=50, cv=2,\n",
    "                    n_jobs=4,\n",
    "                    pre_dispatch = 8,\n",
    "                    random_state=111,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True)\n",
    "\n",
    "opt.fit(X_t, y_t, callback=[return_score])\n",
    "\n",
    "DTclf = opt.best_estimator_\n",
    "\n",
    "add_hypersearch(opt)\n",
    "\n",
    "add_model(DTclf, X_t, y_t, X_val, y_val, \n",
    "          features=all_features, \n",
    "          preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[table['model'] == 'XGBClassifier'].dropna(subset=['val_accuracy'], how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4414b2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = pd.read_csv('hyperparameter_table.csv')\n",
    "table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "plot_precision_recall_curve(clf, X_val, y_val, ax = axes[0])\n",
    "axes[0].set_title('Precision-Recall Curve')\n",
    "\n",
    "plot_roc_curve(clf, X_val, y_val, ax= axes[1])\n",
    "axes[1].set_title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_accuracy = pd.DataFrame(columns= ['accuracy', 'f1_score'],\n",
    "                              index = [x/100 for x in range(60,80)])\n",
    "\n",
    "thresh_accuracy.index.name = 'Threshold'\n",
    "for thresh in range(10, 90):\n",
    "    thresh /= 100\n",
    "    yhat = pd.Series(y_score).apply(lambda x: 1 if x >= thresh else 0)\n",
    "    accuracy = accuracy_score(y_val, yhat)\n",
    "    f1 = f1_score(y_val, yhat)\n",
    "    roc = roc_auc_score(y_val, y_score)\n",
    "    pr = average_precision_score(y_val, y_score)\n",
    "    thresh_accuracy.loc[thresh, 'accuracy'] = accuracy\n",
    "    thresh_accuracy.loc[thresh, 'f1_score'] = f1\n",
    "\n",
    "print('ROC_AUC: ', roc)\n",
    "print('PR_AUC: ', pr)\n",
    "thresh_accuracy = thresh_accuracy.sort_values(by='f1_score', ascending=False)\n",
    "thresh_accuracy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pd.Series(y_score)\n",
    "best_thresh = thresh_accuracy.index[0]\n",
    "yhat = yhat.apply(lambda x: 1 if x >= best_thresh else 0)\n",
    "\n",
    "confusion  = confusion_matrix(y_val, yhat, normalize='true')\n",
    "heatmap(confusion, annot=True, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cfbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(XGBmodel.feature_importances_, index=X_t.columns)\n",
    "importance.sort_values(by=0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb2b84",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('time_series_xgb_best.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6748e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student_predictor_env",
   "language": "python",
   "name": "student_predictor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
